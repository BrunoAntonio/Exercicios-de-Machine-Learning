{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import linalg\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import entropy\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp as multi\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import shapiro\n",
    "from scipy.integrate import cumtrapz\n",
    "from scipy.linalg import eig\n",
    "from numpy.fft import fft\n",
    "\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "#from sklearn.preprocessing import StandardScaler # z = (x - u) / s\n",
    "\n",
    "from copy import deepcopy\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 2\n",
    "\n",
    "def dataset(patient_id):\n",
    "    head=[\"device_id\",\"acc_x\",\"acc_y\",\"acc_z\",\"gyro_x\",\"gyro_y\",\"gyro_z\",\"mag_x\",\"mag_y\",\"mag_z\",\"time\",\"activity\",\"patient_id\"]\n",
    "\n",
    "    #device_1 = pd.read_csv(\"dataset/part{patient}/part{patient}dev1.csv\".format(patient=patient_id),names=head)\n",
    "    device_2 = pd.read_csv(\"dataset/part{patient}/part{patient}dev2.csv\".format(patient=patient_id),names=head)\n",
    "    #device_3 = pd.read_csv(\"dataset/part{patient}/part{patient}dev3.csv\".format(patient=patient_id),names=head)\n",
    "    #device_4 = pd.read_csv(\"dataset/part{patient}/part{patient}dev4.csv\".format(patient=patient_id),names=head)\n",
    "    #device_5 = pd.read_csv(\"dataset/part{patient}/part{patient}dev5.csv\".format(patient=patient_id),names=head)\n",
    "    \n",
    "    \n",
    "    #df=pd.concat([device_1,device_2,device_3,device_4,device_5],axis=0)\n",
    "    df=device_2\n",
    "    df[\"patient_id\"]=patient_id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 2\n",
    "\n",
    "def transformed_dataset():\n",
    "\n",
    "    df_transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range (0,15):\n",
    "        df_transformed = df_transformed.append(dataset(i))\n",
    "    df_transformed = df_transformed.reset_index()\n",
    "        \n",
    "    df_transformed[\"acc_vector\"] = df_transformed[\"acc_x\"]**2+df_transformed[\"acc_y\"]**2+df_transformed[\"acc_z\"]**2\n",
    "    df_transformed[\"gyro_vector\"] = df_transformed[\"gyro_x\"]**2+df_transformed[\"gyro_y\"]**2+df_transformed[\"gyro_z\"]**2\n",
    "    df_transformed[\"mag_vector\"] = df_transformed[\"mag_x\"]**2+df_transformed[\"mag_y\"]**2+df_transformed[\"mag_z\"]**2\n",
    "    \n",
    "    return df_transformed[[\"device_id\",\"acc_vector\",\"gyro_vector\",\"mag_vector\",\"time\",\"activity\",\"patient_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 3.1\n",
    "\n",
    "def vector_boxplot(sensor_id):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "    sns.set_style(\"darkgrid\") \n",
    "    \n",
    "    if sensor_id==\"accelerometer\":\n",
    "        ax=sns.boxplot(data=df_transformed, y=\"acc_vector\",x=\"activity\", palette=\"spring\")\n",
    "      \n",
    "    elif sensor_id==\"gyroscope\":\n",
    "        ax=sns.boxplot(data=df_transformed, y=\"gyro_vector\",x=\"activity\", palette=\"spring\")\n",
    "                \n",
    "    elif sensor_id==\"magnetometer\":\n",
    "        ax=sns.boxplot(data=df_transformed, y=\"mag_vector\",x=\"activity\", palette=\"spring\")\n",
    "        \n",
    "    else:\n",
    "        return \"enter a correct name\"   \n",
    "\n",
    "    ax.set_title(\"Norm from {sensor}\".format(sensor=sensor_id), size=15)  \n",
    "    ax.set_xlabel(\"Activities\",size=15)\n",
    "    \n",
    "    x_labels = np.arange(0,16)\n",
    "    x_new_labels = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\"]\n",
    "    \n",
    "    ax.set_xticklabels(labels=np.arange(0,16),size=12)\n",
    "    ax.set_ylabel(\"\")\n",
    "    plt.xticks(x_labels, x_new_labels, size=12)\n",
    "    plt.savefig(\"Norm from {sensor}\".format(sensor=sensor_id))\n",
    "    \n",
    "    return plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 3.2 by activity\n",
    "\n",
    "def density_by_activity(k, act):\n",
    "    \n",
    "    density_by_activity=pd.DataFrame(columns=[\"density_acc\",\"density_gyro\",\"density_mag\"])\n",
    "    density_by_activity.index.name = \"Activities\"\n",
    "    \n",
    "    for act in range(1,17):\n",
    "        df_transformed = transformed_dataset()\n",
    "        df_transformed = df_transformed[df_transformed[\"activity\"]==act].reset_index(drop=True)\n",
    "        \n",
    "        mean = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].mean()\n",
    "        std = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].std()\n",
    "    \n",
    "        df_transformed[\"outlier_acc\"] = (df_transformed[\"acc_vector\"] < (mean[\"acc_vector\"]-k*std[\"acc_vector\"])) | (df_transformed[\"acc_vector\"] > (mean[\"acc_vector\"]+k*std[\"acc_vector\"]))\n",
    "        df_transformed[\"outlier_gyro\"] = (df_transformed[\"gyro_vector\"] < (mean[\"gyro_vector\"]-k*std[\"gyro_vector\"])) | (df_transformed[\"gyro_vector\"] > (mean[\"gyro_vector\"]+k*std[\"gyro_vector\"]))\n",
    "        df_transformed[\"outlier_mag\"] = (df_transformed[\"mag_vector\"] < (mean[\"mag_vector\"]-k*std[\"mag_vector\"])) | (df_transformed[\"mag_vector\"] > (mean[\"mag_vector\"]+k*std[\"mag_vector\"]))\n",
    "        density_acc = df_transformed[\"outlier_acc\"].sum() / df_transformed[\"acc_vector\"].count() * 100\n",
    "        density_gyro = df_transformed[\"outlier_gyro\"].sum() / df_transformed[\"gyro_vector\"].count() * 100\n",
    "        density_mag = df_transformed[\"outlier_mag\"].sum() / df_transformed[\"mag_vector\"].count() * 100\n",
    "        density_by_activity.loc[act]=[density_acc,density_gyro,density_mag]\n",
    "\n",
    "    return density_by_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 3.2\n",
    "\n",
    "def density(k, act):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    df_transformed = df_transformed[df_transformed[\"activity\"]==act].reset_index(drop=True)\n",
    "    mean = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].mean()\n",
    "    std = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].std()\n",
    "    \n",
    "    df_transformed[\"outlier_acc\"] = (df_transformed[\"acc_vector\"] < (mean[\"acc_vector\"]-k*std[\"acc_vector\"])) | (df_transformed[\"acc_vector\"] > (mean[\"acc_vector\"]+k*std[\"acc_vector\"]))\n",
    "    df_transformed[\"outlier_gyro\"] = (df_transformed[\"gyro_vector\"] < (mean[\"gyro_vector\"]-k*std[\"gyro_vector\"])) | (df_transformed[\"gyro_vector\"] > (mean[\"gyro_vector\"]+k*std[\"gyro_vector\"]))\n",
    "    df_transformed[\"outlier_mag\"] = (df_transformed[\"mag_vector\"] < (mean[\"mag_vector\"]-k*std[\"mag_vector\"])) | (df_transformed[\"mag_vector\"] > (mean[\"mag_vector\"]+k*std[\"mag_vector\"]))\n",
    "    density_acc = df_transformed[\"outlier_acc\"].value_counts()[True] / df_transformed[\"acc_vector\"].count() * 100\n",
    "    density_gyro = df_transformed[\"outlier_gyro\"].value_counts()[True] / df_transformed[\"gyro_vector\"].count() * 100\n",
    "    density_mag = df_transformed[\"outlier_mag\"].value_counts()[True] / df_transformed[\"mag_vector\"].count() * 100\n",
    "    \n",
    "    z_score_outliers=pd.DataFrame(df_transformed[[\"outlier_acc\",\"outlier_gyro\",\"outlier_mag\"]])\n",
    "    \n",
    "    return density_acc, density_gyro, density_mag, z_score_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 3.2\n",
    "\n",
    "def density_activity(k,act):\n",
    "     \n",
    "    df_transformed = transformed_dataset()\n",
    "    df_activity = df_transformed[df_transformed[\"activity\"]==act].copy()\n",
    "    mean = df_activity[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].mean()\n",
    "    std = df_activity[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].std()\n",
    "    \n",
    "    df_activity[\"outlier_acc\"] = (df_activity[\"acc_vector\"] < (mean[\"acc_vector\"]-k*std[\"acc_vector\"])) | (df_activity[\"acc_vector\"] > (mean[\"acc_vector\"]+k*std[\"acc_vector\"]))\n",
    "    df_activity[\"outlier_gyro\"] = (df_activity[\"gyro_vector\"] < (mean[\"gyro_vector\"]-k*std[\"gyro_vector\"])) | (df_activity[\"gyro_vector\"] > (mean[\"gyro_vector\"]+k*std[\"gyro_vector\"]))\n",
    "    df_activity[\"outlier_mag\"] = (df_activity[\"mag_vector\"] < (mean[\"mag_vector\"]-k*std[\"mag_vector\"])) | (df_activity[\"mag_vector\"] > (mean[\"mag_vector\"]+k*std[\"mag_vector\"]))\n",
    "#    density_acc = df_activity[\"outlier_acc\"].value_counts()[True] / df_activity[\"acc_vector\"].count() * 100\n",
    "#    density_gyro = df_activity[\"outlier_gyro\"].value_counts()[True] / df_activity[\"gyro_vector\"].count() * 100\n",
    "#    density_mag = df_activity[\"outlier_mag\"].value_counts()[True] / df_activity[\"mag_vector\"].count() * 100\n",
    "    density_acc = df_activity[df_activity[\"outlier_acc\"]==True].count()[\"outlier_acc\"] / df_activity[\"acc_vector\"].count() * 100\n",
    "    density_gyro = df_activity[df_activity[\"outlier_gyro\"]==True].count()[\"outlier_gyro\"] / df_activity[\"gyro_vector\"].count() * 100\n",
    "    density_mag = df_activity[df_activity[\"outlier_mag\"]==True].count()[\"outlier_mag\"] / df_activity[\"mag_vector\"].count() * 100\n",
    "    \n",
    "    return density_acc, density_gyro, density_mag, df_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 3.3\n",
    "\n",
    "def outlier_Zscore_by_activity(k,act):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    df_transformed = df_transformed[df_transformed[\"activity\"]==act].reset_index(drop=True)\n",
    "    mean = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].mean()\n",
    "    std = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].std()\n",
    "    \n",
    "    Z = (df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]]-mean)/std\n",
    "    outliers = abs(Z)>k\n",
    "    \n",
    "    non_acc_outliers = df_transformed[outliers[\"acc_vector\"]==False][\"acc_vector\"]\n",
    "    non_gyro_outliers = df_transformed[outliers[\"gyro_vector\"]==False][\"gyro_vector\"]\n",
    "    non_mag_outliers = df_transformed[outliers[\"mag_vector\"]==False][\"mag_vector\"]\n",
    "    \n",
    "    df_describe_non_outliers=pd.DataFrame({\"acc_vector\":non_acc_outliers,}).describe().loc[[\"min\",\"max\",\"mean\",\"std\",\"count\"]]\n",
    "    df_describe_non_outliers[\"gyro_vector\"]=pd.DataFrame({\"gyro_vector\":non_gyro_outliers,}).describe().loc[[\"min\",\"max\",\"mean\",\"std\",\"count\"]]\n",
    "    df_describe_non_outliers[\"mag_vctor\"]=pd.DataFrame({\"mag_vector\":non_mag_outliers,}).describe().loc[[\"min\",\"max\",\"mean\",\"std\",\"count\"]]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 10))\n",
    "\n",
    "    sns.distplot(df_transformed[\"acc_vector\"], ax=ax[0], bins=100, label=\"with_outliers\")\n",
    "    sns.distplot(non_acc_outliers, ax=ax[0], color=\"red\", bins=100, label=\"without_outliers\")\n",
    "    ax[0].set_xlim(95,110)\n",
    "    ax[0].set_ylim(0, 0.25)\n",
    "    ax[0].set_title(\"Dataset distribution for acc_vector for activity {}\".format(act), size=14)\n",
    "    ax[0].set_xlabel(\"acc_vector\", size=14) \n",
    "    ax[0].set_ylabel(\"\")\n",
    "    ax[0].legend(prop=dict(size=12))\n",
    "\n",
    "    sns.distplot(df_transformed[\"gyro_vector\"], ax=ax[1], bins=100, label=\"with_outliers\")\n",
    "    sns.distplot(non_gyro_outliers, ax=ax[1], color=\"red\", bins=100, label=\"without_outliers\")\n",
    "    ax[1].set_xlim(0,180)\n",
    "    ax[1].set_ylim(0, 0.01)\n",
    "    ax[1].set_title(\"Dataset distribution for gyro_vector for activity {}\".format(act), size=14)\n",
    "    ax[1].set_xlabel(\"gyro_vector\", size=14)\n",
    "    ax[1].set_ylabel(\"\")\n",
    "    ax[1].legend(prop=dict(size=12))\n",
    "\n",
    "    sns.distplot(df_transformed[\"mag_vector\"], ax=ax[2], bins=100, label=\"with_outliers\")\n",
    "    sns.distplot(non_mag_outliers, ax=ax[2], color=\"red\", bins=100, label=\"without_outliers\")\n",
    "    ax[2].set_ylim(0, 1)\n",
    "    ax[2].set_xlim(1.5,3.5)\n",
    "    ax[2].set_title(\"Dataset distribution for mag_vector for activity {}\".format(act), size=14)\n",
    "    ax[2].set_ylabel(\"\")\n",
    "    ax[2].set_xlabel(\"mag_vector\", size=14)\n",
    "    ax[2].legend(prop=dict(size=12))\n",
    "\n",
    "    plt.savefig(\"Dataset distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "    return df_describe_non_outliers, df_transformed[outliers[\"acc_vector\"]==False][[\"acc_vector\",\"time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 3.3\n",
    "\n",
    "def outlier_Zscore(amostra,k):\n",
    "    \n",
    "    mean = amostra.mean()\n",
    "    std = amostra.std()\n",
    "    Z = (amostra-mean)/std\n",
    "    outliers = abs(Z)>k\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise 3.4\n",
    "\n",
    "#https://stackoverflow.com/questions/29779079/adding-a-scatter-of-points-to-a-boxplot-using-matplotlib\n",
    "\n",
    "def plot_outlier(k,sensor_id):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    boxprops = dict(linewidth=1.0) \n",
    "    \n",
    "\n",
    "    if sensor_id==\"accelerometer\":         \n",
    "        df_transformed[\"outlier_acc_Zscore\"] = outlier_Zscore(df_transformed[\"acc_vector\"],k)        \n",
    "        df_transformed.boxplot(column='acc_vector', by='activity', grid=True, showfliers=False, boxprops = boxprops, patch_artist=True)\n",
    "        \n",
    "        for i in range(0,17):\n",
    "            \n",
    "            y = df_transformed[\"acc_vector\"][(df_transformed[\"activity\"]==i) & (df_transformed[\"outlier_acc_Zscore\"] == True)]\n",
    "            x = np.random.normal(i, 0.01, size=len(y))\n",
    "            plt.plot(x, y, 'ro',markersize = 4, zorder=2)\n",
    "            \n",
    "            y = df_transformed[\"acc_vector\"][(df_transformed[\"activity\"]==i) & (df_transformed[\"outlier_acc_Zscore\"] == False)]\n",
    "            x = np.random.normal(i, 0.01, size=len(y))\n",
    "            plt.plot(x, y, 'bo', markersize = 4, zorder=1)\n",
    "             \n",
    "    elif sensor_id==\"gyroscope\":\n",
    "        df_transformed[\"outlier_gyro_Zscore\"] = outlier_Zscore(df_transformed[\"gyro_vector\"],k)        \n",
    "        df_transformed.boxplot(column='gyro_vector', by='activity', grid=True, showfliers=False, boxprops = boxprops, patch_artist=True)\n",
    "        \n",
    "        for i in range(0,17):           \n",
    "            y = df_transformed[\"gyro_vector\"][(df_transformed[\"activity\"]==i) & (df_transformed[\"outlier_gyro_Zscore\"] == True)]\n",
    "            x = np.random.normal(i, 0.01, size=len(y))\n",
    "            plt.plot(x, y, 'ro', markersize = 4, zorder=2)\n",
    "            \n",
    "            y = df_transformed.gyro_vector[(df_transformed[\"activity\"]==i) & (df_transformed[\"outlier_gyro_Zscore\"] == False)]\n",
    "            x = np.random.normal(i, 0.01, size=len(y))\n",
    "            plt.plot(x, y, 'bo', markersize = 4, zorder=1)\n",
    "                \n",
    "    elif sensor_id==\"magnetometer\":\n",
    "        \n",
    "        df_transformed[\"outlier_mag_Zscore\"] = outlier_Zscore(df_transformed[\"mag_vector\"],k)        \n",
    "        df_transformed.boxplot(column='mag_vector', by='activity', grid=True, showfliers=False, boxprops = boxprops, patch_artist=True)\n",
    "\n",
    "        for i in range(0,17):\n",
    "            y = df_transformed[\"mag_vector\"][(df_transformed[\"activity\"]==i) & (df_transformed[\"outlier_mag_Zscore\"] == True)]\n",
    "            x = np.random.normal(i, 0.01, size=len(y))\n",
    "            plt.plot(x, y, 'ro', markersize = 4, zorder=2)\n",
    "            \n",
    "            y = df_transformed.mag_vector[(df_transformed[\"activity\"]==i) & (df_transformed[\"outlier_mag_Zscore\"] == False)]\n",
    "            x = np.random.normal(i, 0.01, size=len(y))\n",
    "            plt.plot(x, y, 'bo', markersize = 4, zorder=1)\n",
    "        \n",
    "    else:\n",
    "        return \"enter a correct name\"  \n",
    "    \n",
    "    plt.title(\"Zscore outliers from {sensor}\".format(sensor=sensor_id), size=15)  \n",
    "    plt.xlabel(\"Activities\",size=15)\n",
    "    plt.legend(labels=[\"outliers\"], loc=\"upper right\", fontsize=12, handles = plt.plot([], marker=\"o\" ,ls=\"\", color=\"r\"))\n",
    "    plt.savefig(\"Zscore outliers from {sensor}\".format(sensor=sensor_id))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "#Zscore_scaler = StandardScaler()\n",
    "#Zscore_scaler.fit(X)\n",
    "#X_scaled=pd.DataFrame(Zscore_scaler.transform(X), columns=[\"acc_vector\",\"gyro_vector\",\"mag_vector\"])\n",
    "\n",
    "# denormalize data\n",
    "#X = pd.DataFrame(Zscore_scaler.inverse_transform(X_scaled), columns=[\"acc_vector\",\"gyro_vector\",\"mag_vector\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.6\n",
    "\n",
    "#https://www.kaggle.com/andyxie/k-means-clustering-implementation-in-python\n",
    "\n",
    "def KMeans(k, max_iterations,act):\n",
    "    \n",
    "    data = transformed_dataset()\n",
    "    data = data[data[\"activity\"]==act][[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].reset_index(drop=True)\n",
    "\n",
    "# Number of training data\n",
    "    n = data.shape[0]\n",
    "# Number of features in the data\n",
    "    c = data.shape[1]\n",
    "\n",
    "# Generate random centers, here we use sigma and mean to ensure it represent the whole data\n",
    "    mean = np.mean(data, axis = 0).values\n",
    "    std = np.std(data, axis = 0).values\n",
    "    #centers = np.random.randn(k,c)*std + mean\n",
    "    centers= data.sample(n = k).values\n",
    "\n",
    "    centers_old = np.zeros(centers.shape) # to store old centers\n",
    "    centers_new = deepcopy(centers) # Store new centers\n",
    "\n",
    "    data.shape\n",
    "    clusters_label = np.zeros(n)\n",
    "    distances = np.zeros((n,k))\n",
    "\n",
    "    error = np.linalg.norm(centers_new - centers_old)\n",
    "\n",
    "# When, after an update, the estimate of that center stays the same, exit loop\n",
    "    j=0\n",
    "    while not (error < 0.001 or j == max_iterations):\n",
    "        # Measure the distance to every center\n",
    "        for i in range(k):\n",
    "            distances[:,i] = np.linalg.norm(data - centers_new[i], axis=1)\n",
    "        # Assign all data to closest center\n",
    "        clusters_label = np.argmin(distances, axis = 1)\n",
    "    \n",
    "        centers_old = deepcopy(centers_new)\n",
    "        # Calculate mean for every cluster and update the center\n",
    "        for i in range(k):\n",
    "            centers_new[i] = np.mean(data[clusters_label == i], axis=0)                \n",
    "        error = np.linalg.norm(centers_new - centers_old)\n",
    "        j += 1\n",
    "\n",
    "    inertia = np.sum(np.min(distances, axis = 1))\n",
    "   \n",
    "    return centers_new, clusters_label, inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.6\n",
    "\n",
    "def KMeans_plot(clusters_label, act):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    df_transformed = df_transformed[df_transformed[\"activity\"]==act].reset_index(drop=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "    p = ax.scatter(df_transformed[\"acc_vector\"], df_transformed[\"gyro_vector\"], df_transformed[\"mag_vector\"], \n",
    "                   c=clusters_label, cmap=\"rainbow\", zdir=\"-z\")\n",
    "\n",
    "    ax.set_title(\"K-Means clusters for activity {act} with k = 5\".format(act=act), size=15)\n",
    "    ax.set_xlabel(\"acc_vector\", size=15)\n",
    "    ax.set_ylabel(\"gyro_vector\", size=15)\n",
    "    ax.set_zlabel(\"mag_vector\", size=15)\n",
    "    plt.savefig(\"K-means clusters for activity {act} with k = 5\".format(act=act))\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.7\n",
    "\n",
    "def elbow_method(max_clusters, max_it, act):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    df_transformed = df_transformed[df_transformed[\"activity\"]==act][[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].reset_index(drop=True)\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    seq = {}\n",
    "\n",
    "    for i in range(1,max_clusters+1):\n",
    "        _,_,inertia = KMeans(k=i, max_iterations=max_it,act=act)\n",
    "        seq[i] = inertia\n",
    " \n",
    "    plt.plot(list(seq.keys()),list(seq.values()))\n",
    "    \n",
    "    plt.title(\"k-means elbow method for activity {}\".format(act), size=15) \n",
    "    plt.xlabel('Nº of clusters', size=15)\n",
    "    plt.ylabel('Sum of squared distances to the center of cluster', size=15)\n",
    "    plt.savefig(\"K-means elbow method for activity {}\".format(act))\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.7\n",
    "\n",
    "def KMeans_outliers(density, centers_new, clusters_label, act):\n",
    "     \n",
    "    df_transformed = transformed_dataset()\n",
    "    df_transformed = df_transformed[df_transformed[\"activity\"]==act][[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].reset_index(drop=True)\n",
    "    \n",
    "    center = centers_new\n",
    "    df_transformed[\"kmeans_label\"]=clusters_label\n",
    "    \n",
    "    center_points = np.zeros((len(df_transformed),3))\n",
    "    for i in range(0,len(df_transformed)):\n",
    "        label = df_transformed[\"kmeans_label\"][i]\n",
    "        center_points[i][:] = center[label][:]\n",
    "        \n",
    "    df_transformed[\"kmeans_distance\"] = np.sqrt((df_transformed[\"acc_vector\"]-center_points[:,0])**2 + \n",
    "                                         (df_transformed[\"gyro_vector\"]-center_points[:,1])**2 + \n",
    "                                         (df_transformed[\"mag_vector\"]-center_points[:,2])**2)\n",
    "    max_distance = df_transformed.groupby(['kmeans_label'])['kmeans_distance'].max()\n",
    "    max_points = np.zeros((len(df_transformed)))\n",
    "    \n",
    "    for i in range(0,len(df_transformed)):\n",
    "        label = df_transformed[\"kmeans_label\"][i]\n",
    "        max_points[i] = max_distance[label]\n",
    "        \n",
    "    df_transformed[\"kmeans_outliers\"] = ((df_transformed[\"kmeans_distance\"]/max_points) > density) \n",
    "    \n",
    "    x=df_transformed[\"acc_vector\"][df_transformed[\"kmeans_outliers\"] == False]\n",
    "    y=df_transformed[\"gyro_vector\"][df_transformed[\"kmeans_outliers\"] == False]\n",
    "    z=df_transformed[\"mag_vector\"][df_transformed[\"kmeans_outliers\"] == False]\n",
    "\n",
    "    x_outlier=df_transformed[\"acc_vector\"][df_transformed[\"kmeans_outliers\"] == True]\n",
    "    y_outlier=df_transformed[\"gyro_vector\"][df_transformed[\"kmeans_outliers\"] == True]\n",
    "    z_outlier=df_transformed[\"mag_vector\"][df_transformed[\"kmeans_outliers\"] == True]\n",
    "    \n",
    "    colors=df_transformed[\"kmeans_label\"][df_transformed[\"kmeans_outliers\"] == False]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "\n",
    "    ax.scatter(x, y, z, cmap=\"rainbow\", zdir=\"z\",zorder=0, c=colors, alpha=0.6)\n",
    "    ax.scatter(x_outlier, y_outlier, z_outlier, c=\"black\", marker=\"p\", zdir=\"z\", zorder=20, label=\"outliers\")\n",
    "    \n",
    "    ax.set_title(\"K-Means outliers\", size=15)\n",
    "    ax.set_xlabel(\"acc_vector\", size=15)\n",
    "    ax.set_ylabel(\"gyro_vector\", size=15)\n",
    "    ax.set_zlabel(\"mag_vector\", size=15)\n",
    "    ax.legend()\n",
    "    plt.savefig(\"K-means outliers\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    k_means_non_outliers=pd.DataFrame({\"acc_vector\":x,\"gyro_vector\":y,\"mag_vector\":z}).describe().loc[[\"min\",\"max\",\"mean\",\"std\",\"count\"],[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]]\n",
    "    return k_means_non_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.8\n",
    "\n",
    "def outliers_injection(x,k,act):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    df_transformed = df_transformed[df_transformed[\"activity\"]==act].reset_index(drop=True)\n",
    "    \n",
    "    density_acc, density_gyro, density_mag,z_score_outliers = density(k, act)\n",
    "    \n",
    "    df_transformed = df_transformed.join(z_score_outliers)\n",
    "    \n",
    "    mean = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].mean()\n",
    "    std = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].std()\n",
    "    s = np.random.uniform(-1,1)\n",
    "    \n",
    "    range_acc = [abs(min(df_transformed[\"acc_vector\"]) - (mean[\"acc_vector\"]-k*std[\"acc_vector\"])), abs(max(df_transformed[\"acc_vector\"]) - (mean[\"acc_vector\"]+k*std[\"acc_vector\"]))]\n",
    "    z_acc = max(range_acc)  \n",
    "    q_acc = np.random.uniform(0,z_acc)\n",
    "    \n",
    "    range_gyro = [abs(min(df_transformed[\"gyro_vector\"]) - (mean[\"gyro_vector\"]-k*std[\"gyro_vector\"])), abs(max(df_transformed[\"gyro_vector\"]) - (mean[\"gyro_vector\"]+k*std[\"gyro_vector\"]))]\n",
    "    z_gyro = max(range_gyro)  \n",
    "    q_gyro = np.random.uniform(0,z_gyro)\n",
    "    \n",
    "    range_mag = [abs(min(df_transformed[\"mag_vector\"]) - (mean[\"mag_vector\"]-k*std[\"mag_vector\"])), abs(max(df_transformed[\"mag_vector\"]) - (mean[\"mag_vector\"]+k*std[\"mag_vector\"]))]\n",
    "    z_mag = max(range_mag)  \n",
    "    q_mag = np.random.uniform(0,z_mag)\n",
    "        \n",
    "    if (density_acc < x):\n",
    "        index_outliers = np.random.choice(df_transformed.index[~df_transformed['outlier_acc']].tolist(), size=int(np.ceil((x-density_acc)/100*len(df_transformed))), replace = False)\n",
    "        index_outliers = np.append(index_outliers, df_transformed.index[df_transformed['outlier_acc']].tolist())\n",
    "    else:\n",
    "        index_outliers = df_transformed.index[df_transformed['outlier_acc']].tolist()\n",
    "    df_transformed[\"acc_injection\"] = df_transformed[\"acc_vector\"]    \n",
    "    df_transformed.loc[index_outliers, \"acc_injection\"] = mean[0] + s * k * (std[0]+q_acc)\n",
    "    \n",
    "    if (density_gyro < x):  \n",
    "        index_outliers = np.random.choice(df_transformed.index[~df_transformed['outlier_gyro']].tolist(), size=int(np.ceil((x-density_gyro)/100*len(df_transformed))), replace = False)\n",
    "        index_outliers = np.append(index_outliers, df_transformed.index[df_transformed['outlier_gyro']].tolist())\n",
    "    else:\n",
    "        index_outliers = df_transformed.index[df_transformed['outlier_gyro']].tolist()\n",
    "        \n",
    "    df_transformed[\"gyro_injection\"] = df_transformed[\"gyro_vector\"]    \n",
    "    df_transformed.loc[index_outliers, \"gyro_injection\"] = mean[1] + s * k * (std[1]+q_gyro)\n",
    "    \n",
    "    if (density_mag < x):\n",
    "        index_outliers = np.random.choice(df_transformed.index[~df_transformed['outlier_mag']].tolist(), size=int(np.ceil((x-density_mag)/100*len(df_transformed))), replace = False)\n",
    "        index_outliers = np.append(index_outliers, df_transformed.index[df_transformed['outlier_mag']].tolist())\n",
    "    else:\n",
    "        index_outliers = df_transformed.index[df_transformed['outlier_mag']].tolist()\n",
    "    df_transformed[\"mag_injection\"] = df_transformed[\"mag_vector\"]    \n",
    "    df_transformed.loc[index_outliers, \"mag_injection\"] = mean[2] + s * k * (std[2]+q_acc)\n",
    "    \n",
    "    # gyro_injection existe um grande valor minimo devido à amplitude maxima relativamente ao outlier\n",
    "    # o valor médio e máximo estão muito afastados\n",
    "    return df_transformed[[\"acc_injection\",\"gyro_injection\",\"mag_injection\"]].describe().loc[[\"min\",\"max\",\"mean\",\"std\",\"count\"],[\"acc_injection\",\"gyro_injection\",\"mag_injection\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.9 using single value decomposition\n",
    "\n",
    "#def regression(x,Y):\n",
    "#    n, p = np.shape(x)\n",
    "#    X = np.append(np.ones((n,1)),x,axis=1)\n",
    "#    U,s,V = linalg.svd(X)\n",
    "#    S = np.zeros((p+1,n))\n",
    "#    for i in range(0,p):\n",
    "#        S[i,i] = 1/(s[i])\n",
    "#    pseudo_inverse = np.dot(V, np.dot(S,np.transpose(U)))\n",
    "#    beta = np.dot(pseudo_inverse,Y)\n",
    "    \n",
    "#    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.9\n",
    "\n",
    "def regression(x,Y):\n",
    "    n = len(x)\n",
    "    z = np.ones(n)\n",
    "    X = np.transpose(np.vstack([z,x]))\n",
    "\n",
    "    pseudo_inverse = np.dot(linalg.inv((np.dot(np.transpose(X),X))), np.transpose(X))\n",
    "    # pseudo_inverse = linalg.pinv(X)\n",
    "    beta = np.dot(pseudo_inverse,Y)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.9\n",
    "\n",
    "# https://towardsdatascience.com/linear-regression-from-scratch-cd0dee067f72\n",
    "\n",
    "def plot_acc_regression(act,k):\n",
    "\n",
    "    df_transformed = transformed_dataset()\n",
    "    df_transformed = df_transformed[df_transformed[\"activity\"]==act].reset_index(drop=True)\n",
    "    mean = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].mean()\n",
    "    std = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]].std()\n",
    "    \n",
    "    Z = (df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\"]]-mean)/std\n",
    "    outliers = abs(Z)>k\n",
    "    non_acc_outliers = df_transformed[outliers[\"acc_vector\"]==False][[\"acc_vector\", \"time\"]]\n",
    "    \n",
    "    beta=regression(df_transformed[\"time\"],df_transformed[\"acc_vector\"])\n",
    "\n",
    "    df_non_outliers = transformed_dataset()\n",
    "    df_non_outliers = df_transformed[df_transformed[\"activity\"]==act]\n",
    "\n",
    "    beta_non_outliers=regression(non_acc_outliers[\"time\"],non_acc_outliers[\"acc_vector\"])\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))\n",
    "\n",
    "    X = df_transformed[\"time\"]\n",
    "    Y = df_transformed[\"acc_vector\"]\n",
    "    x_max = np.max(X) + 50\n",
    "    x_min = np.min(X) - 50\n",
    "\n",
    "    x = np.linspace(x_min, x_max)\n",
    "    y = beta[0]+beta[1]*x\n",
    "    ax[0].plot(x, y, color='b', label='Linear Regression')\n",
    "    ax[0].scatter(X, Y, color='g', label='Data Point')\n",
    "    ax[0].set_title(\"acc_vector over time for activity 1\", size=14)\n",
    "    ax[0].set_xlabel(\"time\", size=14)\n",
    "    ax[0].set_ylabel(\"acc_vector\", size=14)\n",
    "    ax[0].legend(prop=dict(size=12))\n",
    "\n",
    "    X = non_acc_outliers[\"time\"]\n",
    "    Y = non_acc_outliers[\"acc_vector\"]\n",
    "    x_max = np.max(X) + 50\n",
    "    x_min = np.min(X) - 50\n",
    "\n",
    "    x = np.linspace(x_min, x_max)\n",
    "    y = beta_non_outliers[0]+beta_non_outliers[1]*x\n",
    "    ax[1].plot(x, y, color='b', label='Linear Regression')\n",
    "    ax[1].scatter(X, Y, color='g', label='Data Point')\n",
    "    ax[1].set_title(\"acc_vector without outliers over time for activity 1\", size=14)\n",
    "    ax[1].set_xlabel(\"time\", size=14)\n",
    "    ax[1].set_ylabel(\"acc_vector\", size=14)\n",
    "    ax[1].legend(prop=dict(size=12), loc=1)\n",
    "    \n",
    "    plt.savefig(\"acc_vector over time for activity 1\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.10\n",
    "def linear_injection_anterior_window(n,k,act):    \n",
    "    density_acc, density_gyro, density_mag, df_activity = density_activity(k,act)\n",
    "    df_activity = df_activity.sort_values(by=[\"time\"])\n",
    "    df_activity = df_activity.reset_index(drop=True)\n",
    "    window = np.zeros((len(df_activity)-n+1,4))\n",
    "    for row in range(0, len(df_activity)-n):\n",
    "        x = df_activity.loc[np.arange(row,row+n),\"time\"].reset_index(drop=True)\n",
    "        Y = df_activity.loc[np.arange(row,row+n),\"acc_vector\"]\n",
    "        beta = regression(x,Y)\n",
    "        window[row,:] = [row, row+n, beta[0],beta[1]]\n",
    "        \n",
    "    mean = df_activity[[\"acc_vector\"]].mean()\n",
    "    std = df_activity[[\"acc_vector\"]].std()\n",
    "    \n",
    "    x_density =10\n",
    "    if (density_acc < x_density):\n",
    "        index_outliers = np.random.choice(df_activity.index[~df_activity['outlier_acc']].tolist(), size=int(np.ceil((x_density-density_acc)/100*len(df_activity))), replace = False)\n",
    "        index_outliers = np.append(index_outliers, df_activity.index[df_activity['outlier_acc']].tolist())\n",
    "    else:\n",
    "        index_outliers = df_activity.index[df_activity['outlier_acc']].tolist()\n",
    "    index_outliers.sort()\n",
    "    \n",
    "    \n",
    "    x_outliers = df_activity.loc[index_outliers,\"time\"].reset_index(drop=True)\n",
    "    \n",
    "    error_injection = np.zeros(len(x_outliers))\n",
    "    Y_outlier = np.zeros(len(x_outliers))\n",
    "    for i in range(0,len(index_outliers)):\n",
    "        time_outlier = x_outliers[i]\n",
    "        position_outlier = index_outliers[i]\n",
    "        window_number = position_outlier==window[:,1]\n",
    "        if sum(window_number) == 0:\n",
    "            w = 0\n",
    "        else:\n",
    "            w = np.argwhere(window_number==True)\n",
    "        Y_outlier[i] = np.dot([1,time_outlier],np.transpose(window[w,[2,3]]))\n",
    "        error_injection[i] = abs(df_activity.loc[index_outliers[i],\"acc_vector\"] - Y_outlier[i])    \n",
    "                \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 6))\n",
    "    ax[0].scatter(x_outliers, Y_outlier, color = 'red', zorder=20, label='predicted value')\n",
    "    ax[1].scatter(x_outliers, df_activity.loc[index_outliers,\"acc_vector\"], color = 'blue', zorder=0, alpha=0.6, s=0.3, label='real value')\n",
    "    ax[0].set_title(\"Predicted values using linear regression for activity {}\".format(act), size=15)\n",
    "    ax[0].set_xlabel(\"Time\", size=15)\n",
    "    ax[0].set_ylabel(\"Predicted Acc_vector\", size=15)\n",
    "    ax[1].set_title(\"Real values for activity {}\".format(act), size=15)\n",
    "    ax[1].set_xlabel(\"Time\", size=15)\n",
    "    ax[1].set_ylabel(\"Acc_vector\", size=15)\n",
    "    ax[2].hist(error_injection,bins=40)\n",
    "    ax[2].set_title(\"Histogram of injection error for activity {}\".format(act))\n",
    "    plt.savefig(\"Injection_error_activity{}\".format(act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.10\n",
    "def linear_injection_cross_validation(n,parts,act,k):\n",
    "    rmse = np.zeros((parts-1,1))\n",
    "    density_acc, density_gyro, density_mag, df_activity = density_activity(k,act)\n",
    "    df_activity = df_activity.sort_values(by=[\"time\"])\n",
    "    df_activity = df_activity.reset_index(drop=True)\n",
    "    size = int(np.ceil(len(df_activity)/parts))\n",
    "    for k1 in range(1,parts):\n",
    "        time = df_activity.loc[np.arange(size*k1,min(size*(k1+1),len(df_activity)-1)),\"time\"].reset_index(drop=True)\n",
    "        acc_real = df_activity.loc[np.arange(size*k1,min(size*(k1+1),len(df_activity)-1)),\"acc_vector\"].reset_index(drop=True)\n",
    "        acc_test = np.zeros(len(time))\n",
    "        x = df_activity.loc[np.arange(size*k1-n,size*k1),\"time\"].reset_index(drop=True)\n",
    "        Y = df_activity.loc[np.arange(size*k1-n,size*k1),\"acc_vector\"]\n",
    "        beta = regression(x,Y)\n",
    "        for j in range(0,len(time)):\n",
    "            acc_test[j] = np.dot([1,time[j]],np.transpose(beta))\n",
    "            x = np.append(x[1:], time[j])\n",
    "            Y = np.append(Y[1:], acc_test[j])\n",
    "            beta = regression(x,Y)\n",
    "        error = abs(acc_real-acc_test)\n",
    "        rmse[k1-1,0] = np.sqrt(sum(error**2)/size)\n",
    "    rmse_mean = rmse.mean()\n",
    "    \n",
    "    return rmse_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.10\n",
    "def best_n(act,k):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    \n",
    "    number = int(np.floor(len(df_transformed[df_transformed[\"activity\"]==act].copy())/32)*2)\n",
    "    n = 2*number + number *np.arange(0,3)\n",
    "    rmse_mean = np.zeros((len(n),1))\n",
    "    for j in range(0,len(n)):\n",
    "        rmse_mean[j] = linear_injection_cross_validation(n[j],4,act,k)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "    ax.plot(n,rmse_mean)\n",
    "    ax.set_xlabel(\"n\", size=15)\n",
    "    ax.set_ylabel(\"RMSE mean\", size=15)\n",
    "    ax.set_title(\"RMSE mean for n for anterior regression for activity {}\".format(act), size=15)\n",
    "    plt.savefig(\"RMSE_mean_anterior_activity{}\".format(act))\n",
    "    best = n[np.argmin(rmse_mean)]\n",
    "    linear_injection_anterior_window(best,k,act)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.11\n",
    "def linear_injection_centered_window(n,k,act):    \n",
    "    density_acc, density_gyro, density_mag, df_activity = density_activity(k,act)\n",
    "    df_activity = df_activity.sort_values(by=[\"time\"])\n",
    "    df_activity = df_activity.reset_index(drop=True)\n",
    "    window = np.zeros((len(df_activity)-n+1,3))\n",
    "    for row in range(int(n/2), int(len(df_activity)-n/2)):\n",
    "        positions = [i for i in np.arange(row-n/2,row+n/2) if i not in [row]]\n",
    "        x = df_activity.loc[positions,\"time\"].reset_index(drop=True)\n",
    "        Y = df_activity.loc[positions,\"acc_vector\"].reset_index(drop=True)\n",
    "        beta = regression(x,Y)\n",
    "        window[row,:] = [row, beta[0],beta[1]]\n",
    "         \n",
    "    mean = df_activity[[\"acc_vector\"]].mean()\n",
    "    std = df_activity[[\"acc_vector\"]].std()\n",
    "    \n",
    "    x_density =10\n",
    "    if (density_acc < x_density):\n",
    "        index_outliers = np.random.choice(df_activity.index[~df_activity['outlier_acc']].tolist(), size=int(np.ceil((x_density-density_acc)/100*len(df_activity))), replace = False)\n",
    "        index_outliers = np.append(index_outliers, df_activity.index[df_activity['outlier_acc']].tolist())\n",
    "    else:\n",
    "        index_outliers = df_activity.index[df_activity['outlier_acc']].tolist()\n",
    "    index_outliers.sort()\n",
    "    \n",
    "    \n",
    "    x_outliers = df_activity.loc[index_outliers,\"time\"].reset_index(drop=True)\n",
    "    \n",
    "    error_injection = np.zeros(len(x_outliers))\n",
    "    Y_outlier = np.zeros(len(x_outliers))\n",
    "    for i in range(0,len(index_outliers)):\n",
    "        time_outlier = x_outliers[i]\n",
    "        position_outlier = index_outliers[i]\n",
    "        window_number = position_outlier==window[:,0]\n",
    "        if sum(window_number) == 0:\n",
    "            if position_outlier < window[0,0]:\n",
    "                w = 0\n",
    "            else:\n",
    "                w = len(window)-1  \n",
    "        else:\n",
    "            w = np.argwhere(window_number==True)\n",
    "        Y_outlier[i] = np.dot([1,time_outlier],np.transpose(window[w,[1,2]]))\n",
    "        error_injection[i] = abs(df_activity.loc[index_outliers[i],\"acc_vector\"] - Y_outlier[i])    \n",
    "             \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 6))\n",
    "    ax[0].scatter(x_outliers, Y_outlier, color = 'red', zorder=20, label='predicted value')\n",
    "    ax[1].scatter(x_outliers, df_activity.loc[index_outliers,\"acc_vector\"], color = 'blue', zorder=0, alpha=0.6, s=0.3, label='real value')\n",
    "    ax[0].set_title(\"Predicted values using linear regression for activity {}\".format(act), size=15)\n",
    "    ax[0].set_xlabel(\"Time\", size=15)\n",
    "    ax[0].set_ylabel(\"Predicted Acc_vector\", size=15)\n",
    "    ax[1].set_title(\"Real values for activity {}\".format(act), size=15)\n",
    "    ax[1].set_xlabel(\"Time\", size=15)\n",
    "    ax[1].set_ylabel(\"Acc_vector\", size=15)\n",
    "    ax[2].hist(error_injection,bins=40)\n",
    "    ax[2].set_title(\"Histogram of injection error for activity {}\".format(act))\n",
    "    plt.savefig(\"Injection_error_activity{} for centered window\".format(act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.11\n",
    "def linear_injection_cross_validation_centered(n,parts,act,k):\n",
    "    rmse = np.zeros((parts-2,1))\n",
    "    density_acc, density_gyro, density_mag, df_activity = density_activity(k,act)\n",
    "    df_activity = df_activity.sort_values(by=[\"time\"])\n",
    "    df_activity = df_activity.reset_index(drop=True)\n",
    "    size = int(np.ceil(len(df_activity)/parts))\n",
    "    for k1 in range(1,parts-1):\n",
    "        time = df_activity.loc[np.arange(size*k1,min(size*(k1+1),len(df_activity)-1)),\"time\"].reset_index(drop=True)\n",
    "        acc_real = df_activity.loc[np.arange(size*k1,min(size*(k1+1),len(df_activity)-1)),\"acc_vector\"].reset_index(drop=True)\n",
    "        acc_test = np.zeros(len(time))\n",
    "        x = df_activity.loc[np.arange(size*k1-n/2,size*k1+n/2),\"time\"].reset_index(drop=True)\n",
    "        Y = df_activity.loc[np.arange(size*k1-n/2,size*k1+n/2),\"acc_vector\"].reset_index(drop=True)\n",
    "        beta = regression(x,Y)\n",
    "        for j in range(0,len(time)):\n",
    "            acc_test[j] = np.dot([1,time[j]],np.transpose(beta))\n",
    "            x = np.append(x[1:], time[j])\n",
    "            Y = np.append(Y[1:], acc_test[j])\n",
    "            beta = regression(x,Y)\n",
    "        error = abs(acc_real-acc_test)\n",
    "        rmse[k1-1,0] = np.sqrt(sum(error**2)/size)\n",
    "    rmse_mean = rmse.mean()\n",
    "    \n",
    "    return rmse_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3.11\n",
    "def best_n_centered(act,k):\n",
    "    \n",
    "    df_transformed = transformed_dataset()\n",
    "    \n",
    "    number = int(np.floor(len(df_transformed[df_transformed[\"activity\"]==act].copy())/32)*2)\n",
    "    n = 2*number + number *np.arange(0,3)\n",
    "    rmse_mean = np.zeros((len(n),1))\n",
    "    for j in range(0,len(n)):\n",
    "        rmse_mean[j] = linear_injection_cross_validation_centered(n[j],4,act,k)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "    ax.plot(n,rmse_mean)\n",
    "    ax.set_xlabel(\"n\", size=15)\n",
    "    ax.set_ylabel(\"RMSE mean\", size=15)\n",
    "    ax.set_title(\"RMSE mean for n for centered regression for activity {}\".format(act), size=15)\n",
    "    plt.savefig(\"RMSE_mean_centered_activity{}\".format(act))\n",
    "    best = n[np.argmin(rmse_mean)]\n",
    "    linear_injection_centered_window(best,k,act)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercice 4.1\n",
    "def compare_means(): \n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    df_transformed = transformed_dataset()[[\"acc_vector\",\"gyro_vector\",\"mag_vector\",\"activity\"]]\n",
    "    df_transformed[\"activity\"] = df_transformed[\"activity\"].astype(str)\n",
    "    \n",
    "    means = df_transformed.groupby('activity')['acc_vector','gyro_vector','mag_vector'].mean()\n",
    "    means = means.reset_index()\n",
    "    \n",
    "    vector_names = ['acc_vector','gyro_vector','mag_vector']\n",
    "    means_p = pd.DataFrame()\n",
    "    means_p['activity'] = np.arange(1,17)\n",
    "    norm_p = pd.DataFrame()\n",
    "    norm_p['activity'] = np.arange(1,17)\n",
    "    for v in range(0,3):\n",
    "        vector = vector_names[v]\n",
    "        #means_p = np.zeros((2,16))\n",
    "        for act in range(1,17):\n",
    "            data = df_transformed[df_transformed[\"activity\"]==str(act)][vector]\n",
    "            mean = means[means['activity']==str(act)][vector]\n",
    "            stat, p = stats.ttest_1samp(data, popmean=mean)\n",
    "            means_p.loc[act-1,vector+'_stat'] = stat.values[0]\n",
    "            means_p.loc[act-1,vector+'_p'] = p[0]\n",
    "        \n",
    "        values_per_group = [col for col_name, col in df_transformed.groupby(\"activity\")[vector]]\n",
    "        stat_var, p_var = levene(*values_per_group)\n",
    "        #stat_p = np.zeros((2,16))\n",
    "        for act in range(1,17):\n",
    "            data = df_transformed[df_transformed[\"activity\"]==str(act)][vector]\n",
    "            stat, p = shapiro(data)\n",
    "            norm_p.loc[act-1,vector+'_stat'] = stat\n",
    "            norm_p.loc[act-1,vector+'_p'] = p\n",
    "        \n",
    "        name = vector + ' ~ activity'\n",
    "        lm = ols(name, data=df_transformed).fit()\n",
    "        table = sm.stats.anova_lm(lm)\n",
    "        print(table)\n",
    "        comp = multi.MultiComparison(df_transformed[vector], df_transformed[\"activity\"])\n",
    "        tukey = comp.tukeyhsd()\n",
    "        print(tukey)\n",
    "        \n",
    "        return means_p, norm_p, stat_var, p_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.3 and 4.4\n",
    "def pca_func(X):\n",
    "     \n",
    "    Zscore_scaler = StandardScaler()\n",
    "    Zscore_scaler.fit(X)\n",
    "    X_scaled=pd.DataFrame(Zscore_scaler.transform(X))\n",
    "    \n",
    "    pca = PCA(n_components=0.75)\n",
    "    pca.fit(X_scaled)\n",
    "    \n",
    "    variance = pd.DataFrame(pca.explained_variance_ratio_*100, columns=[\"variance\"])\n",
    "    components = pd.DataFrame(pca.components_)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\")\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 3))\n",
    "\n",
    "    ax = sns.barplot(x=variance.index, y=\"variance\", data=variance, color=\"blue\")\n",
    "\n",
    "    ax.set_ylabel('Percentage of Explained Variance (%)', size=12)\n",
    "    ax.set_xlabel('Principal Components', size=12)\n",
    "    ax.set_title(\"PCA\", size=12)\n",
    "    plt.savefig(\"PCA\")\n",
    "\n",
    "    return variance, components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.4.1\n",
    "\n",
    "def pca_transformed(X):\n",
    "    \n",
    "    Zscore_scaler = StandardScaler()\n",
    "    Zscore_scaler.fit(X)\n",
    "    X_scaled=pd.DataFrame(Zscore_scaler.transform(X))\n",
    "    \n",
    "    pca = PCA(n_components=0.75)\n",
    "    pca.fit(X_scaled)\n",
    "    \n",
    "    components = pd.DataFrame(pca.components_)\n",
    "    \n",
    "    X_pca = np.dot(components,np.transpose(X_scaled))\n",
    "    X_pca = pd.DataFrame(X_pca).transpose()\n",
    "    \n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.4.1\n",
    "\n",
    "# https://python-graph-gallery.com/372-3d-pca-result/\n",
    "\n",
    "def pca_3d_plot():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    df_transformed = transformed_dataset()\n",
    "    df = df_transformed[[\"acc_vector\",\"gyro_vector\",\"mag_vector\",\"activity\"]]\n",
    "    df['activity']=pd.Categorical(df['activity'])\n",
    "\n",
    "    my_color=df['activity'].cat.codes\n",
    "    df = df.drop('activity', 1)\n",
    "    \n",
    "    Zscore_scaler = StandardScaler()\n",
    "    Zscore_scaler.fit(df)\n",
    "    df=pd.DataFrame(Zscore_scaler.transform(df))\n",
    " \n",
    "    # Run The PCA\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(df)\n",
    " \n",
    "    # Store results of PCA in a data frame\n",
    "    result=pd.DataFrame(pca.transform(df), columns=['PCA%i' % i for i in range(3)], index=df.index)\n",
    "\n",
    "    # Plot initialisation\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    a = ax.scatter(result['PCA0'], result['PCA1'], result['PCA2'], c=my_color, cmap=\"rainbow\", s=60, alpha=0.5)\n",
    "\n",
    "    # make simple, bare axis lines through space:\n",
    "    xAxisLine = ((min(result['PCA0']), max(result['PCA0'])), (0, 0), (0,0))\n",
    "    ax.plot(xAxisLine[0], xAxisLine[1], xAxisLine[2], 'r')\n",
    "    yAxisLine = ((0, 0), (min(result['PCA1']), max(result['PCA1'])), (0,0))\n",
    "    ax.plot(yAxisLine[0], yAxisLine[1], yAxisLine[2], 'r')\n",
    "    zAxisLine = ((0, 0), (0,0), (min(result['PCA2']), max(result['PCA2'])))\n",
    "    ax.plot(zAxisLine[0], zAxisLine[1], zAxisLine[2], 'r')\n",
    " \n",
    "    # label the axes\n",
    "    ax.set_xlabel(\"PC1\", size=12)\n",
    "    ax.set_ylabel(\"PC2\", size=12)\n",
    "    ax.set_zlabel(\"PC3\", size=12)\n",
    "    ax.set_title(\"Normalized principal directions\", size=14)\n",
    "    plt.savefig(\"Normalized principal directions\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.4.1\n",
    "\n",
    "#https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "\n",
    "def pca_2d_plot(X_pca):\n",
    "\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "    ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "    ax.set_title('2 component PCA', fontsize = 20)\n",
    "    targets = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    colors = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"lime\",\"indigo\",\"black\",\"grey\",\"sienna\",\"pink\",\"deeppink\",\"darkmagenta\",\"blueviolet\",\"darkorange\"]\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = X_pca['activity'] == target\n",
    "        ax.scatter(X_pca.loc[indicesToKeep, 0], X_pca.loc[indicesToKeep, 1], s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "\n",
    "    plt.savefig(\"pca_2_components\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def dataset_act_vector(act,vector):    \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    vector_x = vector+'_x'\n",
    "    vector_y = vector+'_y'\n",
    "    vector_z = vector+'_z'\n",
    "\n",
    "    for i in range (0,15):\n",
    "        df = df.append(dataset(i))\n",
    "    df = df.reset_index()\n",
    "    df_act_vector = df[df[\"activity\"]==act][[vector_x,vector_y,vector_z,'time']].reset_index(drop=True)\n",
    "    df_act_vector = df_act_vector.sort_values(by=[\"time\"]).reset_index(drop=True)\n",
    "    \n",
    "    return df_act_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def statistical_features(initial,final,act,vector):\n",
    "    \n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    results = df_window.describe()\n",
    "    variance = np.sqrt(results.loc['std']) \n",
    "    results.loc['variance'] = variance\n",
    "    root_mean_square = np.sqrt(np.sum(df_window**2)/df_window.count())\n",
    "    results.loc['rms'] = root_mean_square\n",
    "    vector_x = vector+'_x'\n",
    "    vector_y = vector+'_y'\n",
    "    vector_z = vector+'_z'\n",
    "    derivative = np.zeros((4))\n",
    "    derivative[0] = np.mean(np.gradient(df_window[vector_x],df_window['time']))\n",
    "    derivative[1] = np.mean(np.gradient(df_window[vector_y],df_window['time']))\n",
    "    derivative[2] = np.mean(np.gradient(df_window[vector_z],df_window['time']))\n",
    "    results.loc['av_der'] = derivative\n",
    "    skewness = np.zeros(4)\n",
    "    skewness[0] = skew(df_window[vector_x])\n",
    "    skewness[1] = skew(df_window[vector_y])\n",
    "    skewness[2] = skew(df_window[vector_z])\n",
    "    results.loc['skew'] = skewness\n",
    "    kurt = np.zeros(4)\n",
    "    kurt[0] = kurtosis(df_window[vector_x])\n",
    "    kurt[1] = kurtosis(df_window[vector_y])\n",
    "    kurt[2] = kurtosis(df_window[vector_z])\n",
    "    results.loc['kurtosis'] = kurt\n",
    "    interq_range = results.loc['75%']-results.loc['25%']\n",
    "    results.loc['interq_range'] = interq_range\n",
    "    zero_crossings = np.zeros(4)\n",
    "    #https://stackoverflow.com/questions/3843017/efficiently-detect-sign-changes-in-python\n",
    "    zero_crossings[0] = len(np.where(np.diff(np.sign(df_window[vector_x])))[0])/(final-initial)\n",
    "    zero_crossings[1] = len(np.where(np.diff(np.sign(df_window[vector_y])))[0])/(final-initial)\n",
    "    zero_crossings[2] = len(np.where(np.diff(np.sign(df_window[vector_z])))[0])/(final-initial)\n",
    "    results.loc['zero_crossings'] = zero_crossings\n",
    "    mean_crossings = np.zeros(4)\n",
    "    #https://stackoverflow.com/questions/3843017/efficiently-detect-sign-changes-in-python\n",
    "    mean_crossings[0] = len(np.where(np.diff(np.sign(df_window[vector_x]-results.loc['mean'][vector_x])))[0])/(final-initial)\n",
    "    mean_crossings[1] = len(np.where(np.diff(np.sign(df_window[vector_y]-results.loc['mean'][vector_y])))[0])/(final-initial)\n",
    "    mean_crossings[2] = len(np.where(np.diff(np.sign(df_window[vector_z]-results.loc['mean'][vector_z])))[0])/(final-initial)\n",
    "    results.loc['mean_crossings'] = mean_crossings\n",
    "    pair_correlation = df_window.corr()\n",
    "    results.loc['corr_'+vector_x] = pair_correlation.loc[vector_x]\n",
    "    results.loc['corr_'+vector_y] = pair_correlation.loc[vector_y]\n",
    "    results.loc['corr_'+vector_z] = pair_correlation.loc[vector_z]\n",
    "    spec_entropy = np.zeros(4)\n",
    "    p_data = df_window[vector_x].value_counts()\n",
    "    spec_entropy[0] = entropy(p_data)\n",
    "    p_data = df_window[vector_y].value_counts()\n",
    "    spec_entropy[1] = entropy(p_data)\n",
    "    p_data = df_window[vector_z].value_counts()\n",
    "    spec_entropy[2] = entropy(p_data)\n",
    "    results.loc['spec_entropy'] = spec_entropy\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def moviment_intensity(initial,final,act): \n",
    "    vector=\"acc\"\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = \"acc_x\"\n",
    "    vector_y = \"acc_y\"\n",
    "    vector_z = \"acc_z\"\n",
    "    df_window = df_window[[vector_x,vector_y,vector_z]]\n",
    "    MI = np.sqrt(np.sum(df_window**2,axis=1))\n",
    "    AI = np.sum(MI)/(final-initial)\n",
    "    VI = np.sum((MI-AI)**2)/(final-initial)\n",
    "    \n",
    "    return AI,VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def normalized_signal_magnitude_area(initial,final,act):\n",
    "    vector=\"acc\"\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = \"acc_x\"\n",
    "    vector_y = \"acc_y\"\n",
    "    vector_z = \"acc_z\"\n",
    "    df_window = df_window[[vector_x,vector_y,vector_z]]\n",
    "    SMA = np.sum(np.sum(abs(df_window)))/(final-initial)\n",
    "    \n",
    "    return SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def eigen_values_dominant_directions(initial,final,act):\n",
    "    vector=\"acc\"\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = \"acc_x\"\n",
    "    vector_y = \"acc_y\"\n",
    "    vector_z = \"acc_z\"\n",
    "    df_window = df_window[[vector_x,vector_y,vector_z]]\n",
    "    covariance_matrix = np.cov(df_window)\n",
    "    eigvals,eigvecs = eig(covariance_matrix)\n",
    "    eigvals = np.array(sorted(eigvals, reverse=True)[:2])\n",
    "    \n",
    "    return eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def correlation_acceleration_gravity_heading_directions(initial,final,act):\n",
    "    vector=\"acc\"\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = \"acc_x\"\n",
    "    vector_y = \"acc_y\"\n",
    "    vector_z = \"acc_z\"\n",
    "    df_window = df_window[[vector_x,vector_y,vector_z]]\n",
    "    gravity = df_window[vector_x]\n",
    "    heading = df_window[[vector_y,vector_z]]\n",
    "    heading_norm = np.sqrt(np.sum(heading**2,axis=1))\n",
    "    df_gravity_heading = pd.DataFrame({'gravity':gravity,'heading_norm':heading_norm})\n",
    "    correlation = df_gravity_heading.corr()\n",
    "    correlation = correlation[\"heading_norm\"][0]\n",
    "    \n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def averaged_velocity_heading_direction(initial,final,act):\n",
    "    vector=\"acc\"\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_y = vector+'_y'\n",
    "    vector_z = vector+'_z'\n",
    "    velocity_y = np.sum(cumtrapz(df_window[vector_y],df_window['time']))/(final-initial)\n",
    "    velocity_z = np.sum(cumtrapz(df_window[vector_z],df_window['time']))/(final-initial)\n",
    "    norm_velocity = np.sqrt(velocity_y**2 + velocity_z**2)\n",
    "    \n",
    "    return norm_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def averaged_velocity_gravity_direction(initial,final,act):\n",
    "    vector = \"acc\"\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = vector+'_x'\n",
    "    velocity_x = np.sum(cumtrapz(df_window[vector_x],df_window['time']))/(final-initial)\n",
    "    \n",
    "    return velocity_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def averaged_rotation_angles_gravity_direction(initial,final,act):\n",
    "    vector=\"gyro\"\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = vector+'_x'\n",
    "    av_rotation = np.sum(df_window[vector_x])/(final-initial)\n",
    "    \n",
    "    return av_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def dominant_frequency(initial,final,act,vector):\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = vector+'_x'\n",
    "    vector_y = vector+'_y'\n",
    "    vector_z = vector+'_z'\n",
    "    df_window = df_window[[vector_x,vector_y,vector_z]]\n",
    "    fourier = fft.fft(df_window)\n",
    "    freq = fft.fftfreq(len(fourier))\n",
    "    index_max = np.unravel_index(abs(fourier).argmax(), fourier.shape)\n",
    "    frequency = freq(index_max[0])\n",
    "    \n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def energy(initial,final,act,vector):\n",
    "    df_act_vector = dataset_act_vector(act,vector)\n",
    "    df_window = df_act_vector[(df_act_vector['time']>=initial) & (df_act_vector['time']<=final)].reset_index(drop=True)\n",
    "    vector_x = vector+'_x'\n",
    "    vector_y = vector+'_y'\n",
    "    vector_z = vector+'_z'\n",
    "    df_window = df_window[[vector_x,vector_y,vector_z]]\n",
    "    dc = df_window - df_window.mean()\n",
    "    fourier = np.fft.fft(dc)\n",
    "    en_x,en_y,en_z = abs(fourier).sum(axis=0)/(final-initial)\n",
    "    \n",
    "    return en_x,en_y,en_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def averaged_acceleration_energy(initial,final,act):\n",
    "    vector = 'acc'\n",
    "    en_x,en_y,en_z = energy(initial,final,act,vector)\n",
    "    aae = np.mean([en_x,en_y,en_z])\n",
    "    \n",
    "    return aae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def averaged_rotation_energy(initial,final,act):\n",
    "    vector = 'gyro'\n",
    "    en_x,en_y,en_z = energy(initial,final,act,vector)\n",
    "    are = np.mean([en_x,en_y,en_z])\n",
    "    \n",
    "    return are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "#window_size=40000\n",
    "#act=1\n",
    "#vector=\"acc\"\n",
    "\n",
    "def features_dataset_by_activity(window_size,act,vector):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    data = pd.DataFrame(columns=[vector+\"_x_mean\",vector+\"_y_mean\",vector+\"_z_mean\",\n",
    "                                 vector+\"_x_median\",vector+\"_y_median\",vector+\"_z_median\",\n",
    "                                 vector+\"_x_std\",vector+\"_y_std\",vector+\"_z_std\",\n",
    "                                 vector+\"_x_variance\",vector+\"_y_variance\",vector+\"_z_variance\",\n",
    "                                 vector+\"_x_rms\",vector+\"_y_rms\",vector+\"_z_rms\",\n",
    "                               #  vector+\"_x_av_der\",vector+\"_y_av_der\",vector+\"_z_av_der\",\n",
    "                                 vector+\"_x_skew\",vector+\"_y_skew\",vector+\"_z_skew\",\n",
    "                                 vector+\"_x_kurtosis\",vector+\"_y_kurtosis\",vector+\"_z_kurtosis\",\n",
    "                                 vector+\"_x_interq_range\",vector+\"_y_interq_range\",vector+\"_z_interq_range\",\n",
    "                                 vector+\"_x_zero_crossings\",vector+\"_y_zero_crossings\",vector+\"_z_zero_crossings\",\n",
    "                                 vector+\"_x_mean_crossings\",vector+\"_y_mean_crossings\",vector+\"_z_mean_crossings\",\n",
    "                                 vector+\"_x_corr_acc_x\",vector+\"_y_corr_acc_x\",vector+\"_z_corr_acc_x\",\n",
    "                                 vector+\"_x_corr_acc_y\",vector+\"_y_corr_acc_y\",vector+\"_z_corr_acc_y\",\n",
    "                                 vector+\"_x_corr_acc_z\",vector+\"_y_corr_acc_z\",vector+\"_z_corr_acc_z\",\n",
    "                                 vector+\"_x_spec_entropy\",vector+\"_y_spec_entropy\",vector+\"_z_spec_entropy\",\n",
    "                                 \n",
    "                                 \"acc_MI\",\"acc_VI\",\"acc_SMA\",\"acc_gravity_heading_corr\",\"acc_avg_vel_head\", \"acc_avg_vel_grav\", \n",
    "                                 \"gyro_avg_rot\",vector+\"_x_en\",vector+\"_y_en\",vector+\"_z_en\",\"acc_aae\",\"gyro_are\"])\n",
    "\n",
    "    df_win=pd.DataFrame(columns=[\"init\",\"final\"])\n",
    "\n",
    "    df = dataset_act_vector(act,vector)\n",
    "\n",
    "    for i in range(0,len(df)-window_size,int(window_size/2)):\n",
    "        df_win.loc[i]=[df[\"time\"][i],df[\"time\"][i+window_size]]\n",
    "    \n",
    "    df_win=df_win.reset_index(drop=True)\n",
    "    \n",
    "    for i in range(0,len(df_win)):\n",
    "        initial = df_win[\"init\"][i]\n",
    "        final = df_win[\"final\"][i]\n",
    "    \n",
    "        results = statistical_features(initial,final,act,vector)\n",
    "        ai,vi = moviment_intensity(initial,final,act)\n",
    "        sma = normalized_signal_magnitude_area(initial,final,act)\n",
    "        #eigvals = eigen_values_dominant_directions(initial,final,act)\n",
    "        corr = correlation_acceleration_gravity_heading_directions(initial,final,act)\n",
    "        avg_vel_head = averaged_velocity_heading_direction(initial,final,act)\n",
    "        avg_vel_grav = averaged_velocity_gravity_direction(initial,final,act)\n",
    "        avg_rot = averaged_rotation_angles_gravity_direction(initial,final,act)\n",
    "        en_x,en_y,en_z = energy(initial,final,act,vector)\n",
    "        aae = averaged_acceleration_energy(initial,final,act)\n",
    "        are = averaged_rotation_energy(initial,final,act)\n",
    "    \n",
    "        data.loc[i]=[results.loc[\"mean\"][0],results.loc[\"mean\"][1],results.loc[\"mean\"][2],\n",
    "                     results.loc[\"50%\"][0],results.loc[\"50%\"][1],results.loc[\"50%\"][2],\n",
    "                     results.loc[\"std\"][0],results.loc[\"std\"][1],results.loc[\"std\"][2],\n",
    "                     results.loc[\"variance\"][0],results.loc[\"variance\"][1],results.loc[\"variance\"][2],\n",
    "                     results.loc[\"rms\"][0],results.loc[\"rms\"][1],results.loc[\"rms\"][2],\n",
    "                   #  results.loc[\"av_der\"][0],results.loc[\"av_der\"][1],results.loc[\"av_der\"][2],\n",
    "                     results.loc[\"skew\"][0],results.loc[\"skew\"][1],results.loc[\"skew\"][2],\n",
    "                     results.loc[\"kurtosis\"][0],results.loc[\"kurtosis\"][1],results.loc[\"kurtosis\"][2],\n",
    "                     results.loc[\"interq_range\"][0],results.loc[\"interq_range\"][1],results.loc[\"interq_range\"][2],\n",
    "                     results.loc[\"zero_crossings\"][0],results.loc[\"zero_crossings\"][1],results.loc[\"zero_crossings\"][2],\n",
    "                     results.loc[\"mean_crossings\"][0],results.loc[\"mean_crossings\"][1],results.loc[\"mean_crossings\"][2],\n",
    "                     results.loc[\"corr_acc_x\"][0],results.loc[\"corr_acc_x\"][1],results.loc[\"corr_acc_x\"][2],\n",
    "                     results.loc[\"corr_acc_y\"][0],results.loc[\"corr_acc_y\"][1],results.loc[\"corr_acc_y\"][2],\n",
    "                     results.loc[\"corr_acc_z\"][0],results.loc[\"corr_acc_z\"][1],results.loc[\"corr_acc_z\"][2],\n",
    "                     results.loc[\"spec_entropy\"][0],results.loc[\"spec_entropy\"][1],results.loc[\"spec_entropy\"][2],\n",
    "                     \n",
    "                     ai,vi,sma,corr,avg_vel_head,avg_vel_grav,avg_rot,en_x,en_y,en_z,aae,are]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def feature_correlation_plot(x):\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.heatmap(x)\n",
    "\n",
    "    plt.title(\"Correlation between features\", size=12) \n",
    "    plt.savefig(\"feature_dataset_correlation\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def features_dataset_activities(window_size,vector):\n",
    "\n",
    "    data_final = []\n",
    "    for i in range (1,17):\n",
    "        data = features_dataset_by_activity(window_size,i,vector)\n",
    "        data[\"activity\"] = i\n",
    "        data_final.append(data)\n",
    "    features_data = pd.concat(data_final).reset_index(drop=True)\n",
    "    \n",
    "    return features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercice 4.2\n",
    "\n",
    "def features_dataset_plot(features_data):\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\n",
    "\n",
    "    sns.scatterplot(x=features_data[\"acc_x_mean\"], y=features_data[\"acc_y_mean\"], ax=ax[0], hue=features_data[\"activity\"],palette=\"bright\" )\n",
    "    ax[0].set_title(\"ACC_X_MEAN vs ACC_Y_MEAN\", size=12)\n",
    "    ax[0].set_xlabel(\"ACC_X_MEAN\", size=12) \n",
    "    ax[0].set_ylabel(\"\", size=12)\n",
    "    ax[0].legend(prop=dict(size=7))\n",
    "\n",
    "    sns.scatterplot(x=features_data[\"acc_x_std\"], y=features_data[\"acc_z_std\"], ax=ax[1], hue=features_data[\"activity\"],palette=\"bright\" )\n",
    "    ax[1].set_title(\"ACC_X_STD vs ACC_Y_STD\", size=12)\n",
    "    ax[1].set_xlabel(\"ACC_X_STD\", size=12) \n",
    "    ax[1].set_ylabel(\"\", size=12)\n",
    "    ax[1].legend(prop=dict(size=7))\n",
    "\n",
    "    sns.scatterplot(x=features_data[\"acc_MI\"], y=features_data[\"acc_SMA\"], ax=ax[2], hue=features_data[\"activity\"],palette=\"bright\" )\n",
    "    ax[2].set_title(\"AI vs SMA\", size=12)\n",
    "    ax[2].set_xlabel(\"AI\", size=12) \n",
    "    ax[2].set_ylabel(\"\", size=12)\n",
    "    ax[2].legend(prop=dict(size=7))\n",
    "\n",
    "    sns.scatterplot(x=features_data[\"acc_gravity_heading_corr\"], y=features_data[\"gyro_avg_rot\"], ax=ax[3], hue=features_data[\"activity\"],palette=\"bright\" )\n",
    "    ax[3].set_title(\"CAGH vs ARATG\", size=12)\n",
    "    ax[3].set_xlabel(\"CAGH\", size=12) \n",
    "    ax[3].set_ylabel(\"\", size=12)\n",
    "    ax[3].legend(prop=dict(size=7))\n",
    "\n",
    "    plt.savefig(\"features_dataset\")\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
